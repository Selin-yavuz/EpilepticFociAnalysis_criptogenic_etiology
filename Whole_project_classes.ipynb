{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58488f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334c0dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd71243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de36d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.project_helper_functions_classes import *\n",
    "from ipynb.fs.full.Feature_extraction_classes_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4ad1c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRC_Analysis():\n",
    "    \n",
    "    def __init__(self, stripped_data_folder, original_data_folder, output_root_folder, MRC_output_folder,\n",
    "                 MRC_analysis_features = {'min_step' : 1, 'max_step' : 0,\n",
    "                                          'min_power' :1, 'max_power' : 5,\n",
    "                                         'ROI_shapes': ['circle', 'square'], \n",
    "                                         'primary_rate' : 1, 'secondary_rate' : 1,\n",
    "                                         'calculate_all_powers' : False, 'calculate_all_steps' : False} ):\n",
    "    \n",
    "        self.MRC_analysis_features = MRC_analysis_features\n",
    "        self.stripped_data_folder_path =  os.path.abspath(stripped_data_folder)\n",
    "        self.original_data_folder_path =  os.path.abspath(original_data_folder)\n",
    "        self.mainfolders = take_folder_list(self.stripped_data_folder_path)\n",
    "\n",
    "        ## specify file list for proccess and folder list for record\n",
    "        self.file_names_list, folder_path_list = take_special_file_list(self.mainfolders, \n",
    "                                                                        self.stripped_data_folder_path, self.original_data_folder_path)\n",
    "\n",
    "        self.output_path = os.path.join(os.path.abspath(output_root_folder), MRC_output_folder)\n",
    "        create_folder(self.output_path)\n",
    "        create_mirror_subfolders(folder_paths =folder_path_list, \n",
    "                                 old_root_path = self.stripped_data_folder_path, \n",
    "                                 new_root_path = self.output_path)\n",
    "        ## update files list\n",
    "        min_step , max_step = MRC_analysis_features['min_step'],MRC_analysis_features['max_step']\n",
    "        self.file_names_list = [fn for fn in self.file_names_list if not check_if_MRC_completed(self.output_path, fn[0], self.stripped_data_folder_path, min_step , max_step)]\n",
    "\n",
    "     \n",
    "    \n",
    "    def make_MRC_analysis(self, processor = 2):\n",
    "    \n",
    "        self.run_apply_async_multiprocessing(self.MRC_analysis, self.file_names_list, processor)\n",
    "\n",
    "            \n",
    "    def MRC_analysis(self, file_names):\n",
    "        \n",
    "        min_step = self.MRC_analysis_features['min_step']\n",
    "        max_step = self.MRC_analysis_features['max_step']\n",
    "        min_power = self.MRC_analysis_features['min_power']\n",
    "        max_power = self.MRC_analysis_features['max_power']\n",
    "        ROI_shapes = self.MRC_analysis_features['ROI_shapes']\n",
    "        primary_rate = self.MRC_analysis_features['primary_rate']\n",
    "        secondary_rate = self.MRC_analysis_features['secondary_rate']\n",
    "        calculate_all_powers = self.MRC_analysis_features['calculate_all_powers']\n",
    "        calculate_all_steps = self.MRC_analysis_features['calculate_all_steps']\n",
    "\n",
    "        ## check if MRC files created before as in desired limits     \n",
    "        if check_if_MRC_completed(self.output_path, file_names[0], self.stripped_data_folder_path, min_step, max_step) :        \n",
    "            return(0)\n",
    "\n",
    "\n",
    "        # define inner function to making MRC analysis for different ROI shapes\n",
    "        def MRC_calculation_(roi_shape):\n",
    "            fe = Feature_Extraction(stripped = file_names[0], original = file_names[1], \n",
    "                                    min_power = min_power, max_power = max_power,\n",
    "                                    min_step = min_step, max_step = max_step,\n",
    "                                    ROI_shape = roi_shape, \n",
    "                                    primary_rate = primary_rate, secondary_rate = secondary_rate,\n",
    "                                    all_powers = calculate_all_powers, all_steps = calculate_all_steps)\n",
    "            fe.calculate_features(calculate_MRC = True)\n",
    "            return(fe.MRC_results)\n",
    "\n",
    "        results = list(map(MRC_calculation_, ROI_shapes))\n",
    "\n",
    "         # unite different ROI shape results if 2 shape are givev\n",
    "        if len(results) == 2:\n",
    "            MRC_results = pd.concat([results[0],  results[1]], ignore_index=True) # unite different ROI results\n",
    "\n",
    "        if len(results) == 1:\n",
    "            MRC_results = results[0]\n",
    "\n",
    "        save_results_to_csv(MRC_results, self.output_path, file_names[0], self.stripped_data_folder_path)\n",
    "\n",
    "\n",
    "    def run_apply_async_multiprocessing(self, func, argument_list, num_processes):\n",
    "\n",
    "        pool = Pool(processes=num_processes)\n",
    "\n",
    "        jobs = [pool.apply_async(func=func, args=(*argument,)) if isinstance(argument, tuple) else pool.apply_async(func=func, args=(argument,)) for argument in argument_list]\n",
    "        pool.close()\n",
    "\n",
    "        result_list_tqdm = []\n",
    "        for job in tqdm(jobs):\n",
    "            result_list_tqdm.append(job.get())    \n",
    "        return result_list_tqdm\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caccb76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRC_statistical_analysis():\n",
    "\n",
    "    def __init__(self, stripped_data_folder = 'data/stripped_data', \n",
    "                 output_root_folder = 'output', MRC_output_folder = 'output/MRC_results',\n",
    "                 stat_results_folder = 'MRC_stat_results', \n",
    "              stat_limits = {'auc_limit' : 0.7, 'p_limit' : 0.01}):\n",
    "\n",
    "        ## specifying paths\n",
    "        self.stripped_path =  os.path.abspath(stripped_data_folder)\n",
    "        self.MRC_path = os.path.abspath(MRC_output_folder)\n",
    "\n",
    "        ## create folder for saving statistic results\n",
    "        self.stat_result_path = create_folder(os.path.join(output_root_folder,stat_results_folder))\n",
    "\n",
    "        ## specify main folders lists\n",
    "        self.situations = take_folder_list(self.stripped_path)\n",
    "        \n",
    "        self.lim_auc, self.lim_p = stat_limits['auc_limit'], stat_limits['p_limit']\n",
    "        \n",
    "        \n",
    "    def make_analysis(self, selected_features_path = 'selected_features.csv',\n",
    "                     take_p_csv = True, take_auc_csv = True, take_meaningful_csv = True):\n",
    "                    \n",
    "\n",
    "        control_id = [situation for situation in self.situations if 'c' == situation[0]][0]\n",
    "        patient_id = [situation for situation in self.situations if 'p' == situation[0]][0]\n",
    "        \n",
    "        self.take_p_csv, self.take_auc_csv, self.take_meaningful_csv = take_p_csv, take_auc_csv, take_meaningful_csv\n",
    "       \n",
    "        \n",
    "        ## specify subfolders lists for each situation (control and patients)\n",
    "        subfolders = {}\n",
    "        for situation in self.situations:\n",
    "            subfolders[situation] = take_folder_list(os.path.join(self.stripped_path, situation))\n",
    "        ## specify mutual subfolders for situations\n",
    "        mutual_subfolders = take_mutual_members(subfolders)\n",
    "        \n",
    "        self.column = ['MRI_type', 'shape', 'primary_rate', 'secondary_rate', 'step', 'power']\n",
    "\n",
    "        self.all_p_results, self.all_AUC_results, self.meaningful_results = [], [], []\n",
    "        self.all_selected_features = []\n",
    "\n",
    "        for subfolder in tqdm(mutual_subfolders) :\n",
    "\n",
    "            controls_csv_files_paths = take_spesific_files_paths(os.path.join(self.MRC_path, control_id, subfolder), '.csv')    \n",
    "            patients_csv_files_paths = take_spesific_files_paths(os.path.join(self.MRC_path, patient_id, subfolder), '.csv')\n",
    "\n",
    "            ## calculation of p value (Mann-Whitney U) and AUC (ROC Curve analysis)    \n",
    "            cs = analyse_MRC_results(controls_csv_files_paths, patients_csv_files_paths)   \n",
    "            p_results, AUC_results, meaningful_features = cs.take_stats(folder_type = subfolder, \n",
    "                                                                        auc_limit = self.lim_auc, p_limit = self.lim_p)\n",
    "\n",
    "            selected_features = cs.power_analysis()\n",
    "            self.all_selected_features.extend(selected_features)\n",
    "\n",
    "            ## store results \n",
    "            if self.take_p_csv:\n",
    "                self.all_p_results.extend(p_results)\n",
    "            if self.take_auc_csv :\n",
    "                self.all_AUC_results.extend(AUC_results)\n",
    "            if self.take_meaningful_csv :\n",
    "                self.meaningful_results.extend(meaningful_features)\n",
    "                \n",
    "                \n",
    "    def make_collective_analysis(self, selected_features_path = 'selected_features_coll.csv',\n",
    "                     take_p_csv = True, take_auc_csv = True, take_meaningful_csv = True,\n",
    "                     sequences = {'t1': ['t1_tra', 't1_sag'], 't2' : ['t2_cor', 't2_tra']},\n",
    "                    case_info_excel_file = 'output/MRI_informations.xlsx'):\n",
    "        \n",
    "        self.take_p_csv, self.take_auc_csv, self.take_meaningful_csv = take_p_csv, take_auc_csv, take_meaningful_csv\n",
    "        ## specify column names for identify values in lists\n",
    "        self.column = ['sequence', 'shape', 'primary_rate', 'secondary_rate', 'step', 'power']\n",
    "        \n",
    "        control_id = [situation for situation in self.situations if 'c' == situation[0]][0]\n",
    "        patient_id = [situation for situation in self.situations if 'p' == situation[0]][0]\n",
    "                \n",
    "        self.all_p_results, self.all_AUC_results, self.meaningful_results = [], [], []\n",
    "        self.all_selected_features = []\n",
    "\n",
    "        for key in tqdm(sequences.keys()):\n",
    "\n",
    "            controls_csv_files_paths, patients_csv_files_paths = {}, {}\n",
    "\n",
    "            for subfolder in sequences[key] : \n",
    "\n",
    "                controls_csv_files_paths[subfolder] = take_spesific_files_paths(os.path.join(self.MRC_path, control_id, subfolder),'.csv')        \n",
    "                patients_csv_files_paths[subfolder] = take_spesific_files_paths(os.path.join(self.MRC_path, patient_id, subfolder), '.csv')\n",
    "\n",
    "            ## calculation of p value (Mann-Whitney U) and AUC (ROC Curve analysis) \n",
    "            cs = analyse_MRC_results(collective_evaluation=True)      \n",
    "            cs.activate_collective_evaluation(controls_csv_files_paths, patients_csv_files_paths, \n",
    "                                    sequence_folders = sequences[key], caseid_info_file=case_info_excel_file, \n",
    "                                              control_id = control_id, patient_id = patient_id)    \n",
    "            p_results, AUC_results, meaningful_features = cs.take_stats(folder_type = key, \n",
    "                                                                        auc_limit = self.lim_auc, p_limit = self.lim_p)        \n",
    "            selected_features = cs.power_analysis()\n",
    "            self.all_selected_features.extend(selected_features)    \n",
    "            ## store results\n",
    "            if self.take_p_csv:\n",
    "                self.all_p_results.extend(p_results)\n",
    "            if self.take_auc_csv:\n",
    "                self.all_AUC_results.extend(AUC_results)\n",
    "            if self.take_meaningful_csv:    \n",
    "                self.meaningful_results.extend(meaningful_features)\n",
    "                \n",
    "                \n",
    "        \n",
    "    def save_results(self, p_csv_path = 'p_values.csv', auc_csv_path = 'auc_values.csv', \n",
    "                      meaningful_stat_csv_path = 'meaningful_stats.csv', \n",
    "                     selected_features_path = 'selected_features.csv',\n",
    "                     sort_columns = True):\n",
    "    \n",
    "        ## save results to csv files\n",
    "        save_stat_to_csv(self.all_selected_features, labels = self.column  + ['AUC_value', 'p_value'], \n",
    "                             path = os.path.join(self.stat_result_path, selected_features_path), \n",
    "                             sort_columns = sort_columns,\n",
    "                             ascending_order = False, sorting_columns = ['AUC_value', 'p_value'])       \n",
    "        if self.take_p_csv: \n",
    "            save_stat_to_csv(self.all_p_results, labels = self.column + ['p_value'], \n",
    "                             path = os.path.join(self.stat_result_path, p_csv_path), sort_columns = sort_columns,\n",
    "                             ascending_order = True, sorting_columns = ['p_value'])\n",
    "        if self.take_auc_csv :\n",
    "            save_stat_to_csv(self.all_AUC_results, labels = self.column + ['AUC_value'], \n",
    "                             path = os.path.join(self.stat_result_path, auc_csv_path), sort_columns = sort_columns,\n",
    "                             ascending_order = False, sorting_columns = ['AUC_value'])\n",
    "        if self.take_meaningful_csv :\n",
    "            save_stat_to_csv(self.meaningful_results, labels = self.column + ['AUC_value', 'p_value'], \n",
    "                         path = os.path.join(self.stat_result_path, meaningful_stat_csv_path), sort_columns = sort_columns,\n",
    "                         ascending_order = False, sorting_columns = ['AUC_value', 'p_value'])\n",
    "\n",
    "     \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d8a87da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EPE_Analysis__():\n",
    "\n",
    "    def __init__(self, stripped_data_folder = 'data/stripped_data',\n",
    "            original_data_folder = 'data/ordered_data',\n",
    "            output_root_folder = 'output' ,\n",
    "            stat_results = 'EPE_stat_results',\n",
    "            feature_out = 'features'):\n",
    "\n",
    "        ## specifying paths\n",
    "        self.stripped_path =  os.path.abspath(stripped_data_folder)\n",
    "        self.original_path =  os.path.abspath(original_data_folder)\n",
    "        self.output_path = os.path.abspath(output_root_folder)\n",
    "        self.EPE_stat_results_folder_path = create_folder(os.path.join(self.output_path, stat_results))\n",
    "        self.feature_output_folder_path = create_folder(os.path.join(self.output_path, feature_out))\n",
    "        ## specify main folders lists\n",
    "        self.situations = take_folder_list(self.stripped_path)        \n",
    "        ## specify controls and patients folders' names    \n",
    "        self.control_id = [situation for situation in self.situations if 'c' == situation[0]][0]\n",
    "        self.patient_id = [situation for situation in self.situations if 'p' == situation[0]][0]\n",
    "        ## specify all file names lists\n",
    "        self.file_list, folder_path_list = take_special_file_list(self.situations, \n",
    "                                                             self.stripped_path, self.original_path)\n",
    "\n",
    "                \n",
    "    def make_analysis(self, features_csv_path = 'MRC_stat_results/selected_features.csv', \n",
    "                      EPE_stat_file_name = 'results.csv',\n",
    "                      specificity_min = 0.9, sensitivity_min = 0.6,\n",
    "                      per_case_value_limit = 1000,\n",
    "                      record_features = True,\n",
    "                      follow_proccess = 'only_stats',\n",
    "                     processor_number = 4):\n",
    "        \n",
    "        ## import features' informations\n",
    "        features_path = os.path.join(self.output_path, features_csv_path)        \n",
    "        features_infos = pd.read_csv(features_path)\n",
    "        ## recording file paths based on single folders clinical conditions(situation):\n",
    "        file_paths = {}\n",
    "        for folder in features_infos['MRI_type'].unique():\n",
    "            file_paths[folder] = special_filter_path(self.file_list, self.situations, [folder])\n",
    "        ##start dataframe for store results    \n",
    "        df_stat = pd.DataFrame()                            \n",
    "\n",
    "        for key in file_paths.keys():\n",
    "            ## specify features belong to specific folder (key)\n",
    "            features = features_infos[features_infos['MRI_type'] == key]\n",
    "            EPE = EPE_analysis(self.control_id, self.patient_id, PCVL  = per_case_value_limit, \n",
    "                               feature_output_folder = self.feature_output_folder_path,\n",
    "                               follow_proccess = follow_proccess)\n",
    "            EPE_df = EPE.activate_EPE_analysis(features, \n",
    "                                               file_paths[key][self.control_id],  \n",
    "                                               file_paths[key][self.patient_id],\n",
    "                                               specificity_min = specificity_min, \n",
    "                                               sensitivity_min = sensitivity_min)    \n",
    "            df_stat = pd.concat([EPE_df, df_stat], axis = 0, ignore_index=True)\n",
    "        \n",
    "            ## save results        \n",
    "            result_output_path =  os.path.join(self.EPE_stat_results_folder_path, key + '-' + EPE_stat_file_name)\n",
    "            df_stat.sort_values(by = 'specificity(EPE)', ascending= False, inplace=True)\n",
    "            df_stat.to_csv(result_output_path, index =False) \n",
    "\n",
    "       \n",
    "        \n",
    "    def make_collective_analysis(self, features_collective_csv_path = 'MRC_stat_results/selected_features_coll.csv', \n",
    "                      coll_EPE_stat_file_name = 'coll_results.csv',\n",
    "                      sequences = {'t1': ['t1_tra', 't1_sag'], 't2' : ['t2_cor', 't2_tra']},\n",
    "                      case_info_excel_file = 'output/MRI_informations.xlsx',\n",
    "                      specificity_min = 0.9, sensitivity_min = 0.6,\n",
    "                      per_case_value_limit = 1000,\n",
    "                      record_features = True,\n",
    "                      follow_proccess = 'only_stats',\n",
    "                     processor_number = 2):\n",
    "        \n",
    "        ## import features' informations\n",
    "        collective_features_path = os.path.join(self.output_path, features_collective_csv_path)     \n",
    "        features_coll_infos = pd.read_csv(collective_features_path)\n",
    "        ## recording file paths based on single folders clinical conditions(situation):\n",
    "        file_paths_coll = {}\n",
    "        for sq in features_coll_infos['sequence'].unique():\n",
    "            file_paths_coll[sq] = special_filter_path(self.file_list, self.situations, sequences[sq])\n",
    "        ##start dataframe for store results\n",
    "        df_stat = pd.DataFrame()         \n",
    " \n",
    "        for key in file_paths_coll.keys():\n",
    "            ## specify features belong to specific folder (key)\n",
    "            features = features_coll_infos[features_coll_infos['sequence'] == key]\n",
    "            EPE = EPE_analysis(self.control_id, self.patient_id, PCVL  = per_case_value_limit, \n",
    "                               feature_output_folder = self.feature_output_folder_path,\n",
    "                               follow_proccess = follow_proccess)\n",
    "            EPE_df = EPE.activate_EPE_analysis(features, \n",
    "                                               file_paths_coll[key][self.control_id],  \n",
    "                                               file_paths_coll[key][self.patient_id],\n",
    "                                               specificity_min = specificity_min, \n",
    "                                               sensitivity_min = sensitivity_min,\n",
    "                                              activate_collective_analysis = True, \n",
    "                                              info_path = case_info_excel_file, \n",
    "                                               sequence_folders = sequences[key])   \n",
    "            df_stat = pd.concat([EPE_df, df_stat], axis = 0, ignore_index=True)\n",
    "        \n",
    "            ## save results        \n",
    "            result_output_path =  os.path.join(self.EPE_stat_results_folder_path, key + '-' + coll_EPE_stat_file_name)\n",
    "            df_stat.sort_values(by = 'specificity(EPE)', ascending= False, inplace=True)\n",
    "            df_stat.to_csv(result_output_path, index =False)\n",
    "            \n",
    "\n",
    "        \n",
    "                \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af25de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data(root_folder_path, folder_name,  folder_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    situations = ['controls', 'patients']\n",
    "    # create folders\n",
    "    create_new_folder(os.path.join(root_folder_path, folder_name)) \n",
    "    for situation in situations:        \n",
    "        create_new_folder(os.path.join(root_folder_path, folder_name, situation))\n",
    "        for folder in folder_list:\n",
    "            create_new_folder(os.path.join(root_folder_path, folder_name, situation, folder))\n",
    " \n",
    "    def arr_proccess(arr):\n",
    "        sub_arr = np.array([1,2,3,2,4])\n",
    "        sub_arr = np.tile(sub_arr, (5,1))\n",
    "        for i in range(5) : \n",
    "            for j in  np.arange(0, 100, 5):\n",
    "                for k in  np.arange(0, 100, 5):\n",
    "                    arr[i, j:j+5, k:k+5] = sub_arr\n",
    "                    \n",
    "        arr[2, 48:53, 48:53] = np.ones((5,5)) + 1\n",
    "\n",
    "        return(arr)\n",
    "    \n",
    "    coords = [2, 50, 50]\n",
    "    \n",
    "     \n",
    "    for folder in folder_list:\n",
    "        \n",
    "        control_path = os.path.join(root_folder_path, folder_name, 'controls', folder)\n",
    "        patient_path = os.path.join(root_folder_path, folder_name, 'patients', folder)\n",
    "    \n",
    "        for i in range (5):        \n",
    "            arr = np.zeros((5,100,100))   \n",
    "            arr = arr_proccess(arr)\n",
    "            ##for controls\n",
    "            controls_image = nib.Nifti1Image(arr, affine=np.eye(4))\n",
    "            file_name = 'case' + str(i+1) + '.nii.gz'\n",
    "            file_path =  os.path.join(control_path, file_name)\n",
    "            if not os.path.isfile(file_path):\n",
    "                nib.save(controls_image, file_path)\n",
    "\n",
    "\n",
    "            ## for patients\n",
    "            arr[coords[0]][coords[1]][coords[2]] = 6\n",
    "            patient_image = nib.Nifti1Image(arr, affine=np.eye(4))\n",
    "            file_name = 'case' + str(i+1) + '.nii.gz'\n",
    "            file_path = os.path.join(patient_path, file_name)\n",
    "            if not os.path.isfile(file_path):\n",
    "                nib.save(patient_image,  file_path)\n",
    "                \n",
    "    return(coords)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f943c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_EF_Coordinates(estimated_coordinates, EF_coordinates):\n",
    "    for a,b,c in estimated_coordinates:\n",
    "        if [a,b,c] != EF_coordinates:\n",
    "            print(\"The test is failed. Coordinates are not matching !\")\n",
    "            return(0)\n",
    "    print(\" The test is passed. Algorithm is working properly! \")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7edcf9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_excel_file(excel_path, situations, subfolder_list):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if not os.path.isfile(excel_path):        \n",
    "        with pd.ExcelWriter(excel_path) as writer:  \n",
    "            for situation in situations:\n",
    "                for subfolder in subfolder_list:\n",
    "                    sheetname = situation + '_' + subfolder \n",
    "                    df = pd.DataFrame()\n",
    "                    df['input_name'] = ['a', 'b', 'c', 'd', 'e']\n",
    "                    df['case_name']  = ['case1', 'case2', 'case3', 'case4', 'case5']\n",
    "                    df.to_excel(writer, sheet_name = sheetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c75fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_folder(folder_path):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7744eee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
